{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import modules.cosmos_functions as cf\n",
    "import numpy as np\n",
    "import pprint\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to display images\n",
    "def reverse_normalize(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    image = image.clone()\n",
    "    for i in range(3):\n",
    "        image[i] = (image[i] * std[i]) + mean[i]\n",
    "    return image\n",
    "\n",
    "def show_batch(test_d):\n",
    "    # Get the first batch of data from the DataLoader\n",
    "    data_test = next(iter(test_d))\n",
    "\n",
    "    # Retrieve the first tensor and its corresponding label\n",
    "    image_test = data_test[0][0]\n",
    "    label_test = data_test[1][0]\n",
    "\n",
    "    # Reverse the normalization of the image\n",
    "    image_test = reverse_normalize(image_test)\n",
    "\n",
    "    # Convert the image tensor to a NumPy array and transpose the dimensions\n",
    "    np_image_test = image_test.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(np_image_test)\n",
    "    plt.title(f'{label_test}, {image_test.shape}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is 'mps' Thus a tensor will look like this: tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# set the device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "x = torch.ones(1, device=device)\n",
    "\n",
    "print(f\"Device is '{device}' Thus a tensor will look like this: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the CNN model with input (3, 32, 32) and output (4, 1, 1)\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "    \n",
    "#     #-------------------------------------------------------\n",
    "    \n",
    "#     def __init__(self, dropout=0):\n",
    "#         self.dropout = dropout\n",
    "        \n",
    "\n",
    "#         # Because we inherit from Module base class\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # RGB input, 6 filters, kernel of 5 x 5\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "#         # Filter is 2 x 2 with a stride of 2 (defined once, used two times)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "#         # in_channels = 6 because self.conv1 output has 6 channels\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "#         # Fully connected layer matched on output of conv2 layer\n",
    "#         self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        \n",
    "#         # Dropout layer1\n",
    "#         self.dropout1 = nn.Dropout(self.dropout)    \n",
    "\n",
    "#         # Dropout layer2\n",
    "#         self.dropout2 = nn.Dropout(self.dropout)\n",
    "\n",
    "#         # Fully connected layer\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "#         # We only have 2 labels\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "#     #-------------------------------------------------------\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         # Convolution with relu layers\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "#         # To match the output of the conv2 layer onto the first fully connected layer\n",
    "#         # Like reshape() but makes no copy (reuses underlaying data)\n",
    "#         x = x.view(-1, 16 * 13 * 13)\n",
    "        \n",
    "#         # Fully connected layers\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.dropout2(x)\n",
    "        \n",
    "#         # No activation on final layer \n",
    "#         return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        \n",
    "        # Calculate the output size after pooling and convolutions\n",
    "        self.fc_input_size = 16 * 53 * 53  # Adjusted for input size 224x224\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 120)\n",
    "        self.dropout1 = nn.Dropout(self.dropout)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.dropout2 = nn.Dropout(self.dropout)\n",
    "        self.fc3 = nn.Linear(84,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, self.fc_input_size)  # Flatten the output of the conv layer automatically\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = F.softmax(self.fc3(x), dim=1)  # softmax on dim 1 to get probabilities for apple\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the 1st img in the dataset\n",
    "# show_batch(test_d)\n",
    "# print(test_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../storage/data/generated/20230607-234930_pinky_acc.pt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_model_path = \"../storage/data/generated/20230607-234930_pinky_acc.pt\"   # test to test 224x224\n",
    "# imported_model_path = \"../storage/data/generated/20230605-134750_pinky_acc.pt\"  # high accuracy\n",
    "# imported_model_path = cf.load_pth('20230605_160852_pinky')  # issues; WIP\n",
    "imported_model_path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.4333\n",
      "Normal Apple accuracy: 0.0000\n",
      "Abnormal Apple accuracy: 0.5417\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the model\n",
    "model = CNN()\n",
    "model_import_path = imported_model_path\n",
    "model.load_state_dict(torch.load(model_import_path))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification/Test\"\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = ImageFolder(dataset_path, transform=transform)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the label dictionary\n",
    "labels_dict = {\n",
    "    'Blotch_Apple': 0,\n",
    "    'Normal_Apple': 1,\n",
    "    'Rot_Apple': 2,\n",
    "    'Scab_Apple': 3\n",
    "}\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    # Track the overall test accuracy and accuracy by each type of apple\n",
    "    overall_correct = 0\n",
    "    overall_total = 0\n",
    "    normal_correct = 0\n",
    "    normal_total = 0\n",
    "    abnormal_correct = 0\n",
    "    abnormal_total = 0\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update accuracy counts\n",
    "        overall_correct += (predicted == labels).sum().item()\n",
    "        overall_total += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy for normal apples vs. abnormal apples\n",
    "        normal_mask = labels == labels_dict['Normal_Apple']\n",
    "        abnormal_mask = ~normal_mask\n",
    "        normal_correct += (predicted[normal_mask] == labels[normal_mask]).sum().item()\n",
    "        normal_total += normal_mask.sum().item()\n",
    "        abnormal_correct += (predicted[abnormal_mask] == labels[abnormal_mask]).sum().item()\n",
    "        abnormal_total += abnormal_mask.sum().item()\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = overall_correct / overall_total\n",
    "\n",
    "    # Calculate accuracy for normal apples and abnormal apples separately\n",
    "    normal_accuracy = normal_correct / normal_total if normal_total != 0 else 0.0\n",
    "    abnormal_accuracy = abnormal_correct / abnormal_total if abnormal_total != 0 else 0.0\n",
    "\n",
    "    # Print overall accuracy\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # Print accuracy for normal apples and abnormal apples separately\n",
    "    print(f\"Normal Apple accuracy: {normal_accuracy:.4f}\")\n",
    "    print(f\"Abnormal Apple accuracy: {abnormal_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "test_model(model, test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pink_lady-bMzUwwsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
