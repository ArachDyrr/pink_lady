{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import modules.cosmos_functions as cf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to use in the tests \n",
    "\n",
    "# functions to display images\n",
    "def reverse_normalize(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    image = image.clone()\n",
    "    for i in range(3):\n",
    "        image[i] = (image[i] * std[i]) + mean[i]\n",
    "    return image\n",
    "\n",
    "def show_batch(test_d):\n",
    "    # Get the first batch of data from the DataLoader\n",
    "    data_test = next(iter(test_d))\n",
    "\n",
    "    # Retrieve the first tensor and its corresponding label\n",
    "    image_test = data_test[0][0]\n",
    "    label_test = data_test[1][0]\n",
    "\n",
    "    # Reverse the normalization of the image\n",
    "    image_test = reverse_normalize(image_test)\n",
    "\n",
    "    # Convert the image tensor to a NumPy array and transpose the dimensions\n",
    "    np_image_test = image_test.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(np_image_test)\n",
    "    plt.title(f'{label_test}, {image_test.shape}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# function to test the model\n",
    "def test_model(model, datasetPath):\n",
    "    model.eval()    \n",
    "\n",
    "    # Load the test dataset\n",
    "    dataset_path = datasetPath\n",
    "    transform = T.Compose([\n",
    "        T.Resize((128, 128)),\n",
    "        T.ToTensor()\n",
    "                \n",
    "])\n",
    "    dataset = ImageFolder(dataset_path, transform=transform)\n",
    "    test_dataloader = DataLoader(dataset, batch_size=120, shuffle=False)\n",
    "\n",
    "    labels_dict = dataset.class_to_idx\n",
    "\n",
    "    # Track the overall test accuracy and accuracy by each type of apple\n",
    "    overall_correct = 0\n",
    "    overall_total = 0\n",
    "    normal_correct = 0\n",
    "    normal_total = 0\n",
    "    abnormal_correct = 0\n",
    "    abnormal_total = 0\n",
    "\n",
    "    # Initialize the confusion matrix\n",
    "    num_classes = len(labels_dict)\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update accuracy counts\n",
    "        overall_correct += (predicted == labels).sum().item()\n",
    "        overall_total += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy for normal apples vs. abnormal apples\n",
    "        normal_mask = labels == labels_dict['Normal_Apple']\n",
    "        abnormal_mask = ~normal_mask\n",
    "        normal_correct += (predicted[normal_mask] == labels[normal_mask]).sum().item()\n",
    "        normal_total += normal_mask.sum().item()\n",
    "        abnormal_correct += (predicted[abnormal_mask] == labels[abnormal_mask]).sum().item()\n",
    "        abnormal_total += abnormal_mask.sum().item()\n",
    "\n",
    "        # Update the confusion matrix\n",
    "        for true_label, predicted_label in zip(labels.cpu().numpy(), predicted.cpu().numpy()):\n",
    "            confusion_matrix[true_label][predicted_label] += 1\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = overall_correct / overall_total\n",
    "\n",
    "    # Calculate accuracy for normal apples and abnormal apples separately\n",
    "    normal_accuracy = normal_correct / normal_total if normal_total != 0 else 0.0\n",
    "    abnormal_accuracy = abnormal_correct / abnormal_total if abnormal_total != 0 else 0.0\n",
    "\n",
    "    # Print overall accuracy\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # Print accuracy for normal apples and abnormal apples separately\n",
    "    print(f\"Normal Apple accuracy: {normal_accuracy:.4f}\")\n",
    "    print(f\"Abnormal Apple accuracy: {abnormal_accuracy:.4f}\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print()\n",
    "    print(labels_dict)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    good = confusion_matrix[1]\n",
    "    bad = sum(confusion_matrix) - good\n",
    "    create_batch = lambda good, bad: [0 for _ in range(good)] + [1 for _ in range(bad)]\n",
    "    batchList = create_batch(good, bad)\n",
    "\n",
    "    from modules.AQL_functions import AQL_classificationmaker, AQL_classification\n",
    "    classification = AQL_classificationmaker(good, , [0.4, 6.5, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "x = torch.ones(1, device=device)\n",
    "\n",
    "print(f\"Device is '{device}' Thus a tensor will look like this: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the resnet18 model for testing the test dataset with the trained model\n",
    "# import the resnet18 model\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT  #weights=ResNet18_Weights.IMAGENET1K_V1 is the current default\n",
    "model = resnet18(weights=weights)  \n",
    "\n",
    "# freeze the model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# change the last layer of the model to fit the number of classes in the dataset\n",
    "model.fc = nn.Linear(512, 4)\n",
    "    \n",
    "# change the last layer of the model to fit the number of classes in the dataset\n",
    "model.fc = nn.Linear(512, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the 1st img in the dataset\n",
    "# show_batch(test_d)\n",
    "# print(test_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imported_model_path = \"../storage/data/generated/20230605-134750_pinky_acc.pt\"  # high accuracy\n",
    "# imported_model_path = cf.load_pth('20230605_160852_pinky')  # issues; WIP\n",
    "# imported_model_path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_resized_128/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/20230608-233306_pinky_acc.pt\"   # test to 128x128 accuracy\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_resized_128/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/20230608-233306_pinky_loss.pt\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_model(model, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification_unedited/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/20230608-233306_pinky_acc.pt\"   # test to 128x128 accuracy\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print ('higest accuracy model')\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification_unedited/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/20230608-233306_pinky_loss.pt\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('lowest loss model')\n",
    "test_model(model, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification_unedited/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/20230608-233306_pinky_final.pt\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Final model\")\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification_unedited/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/model_safe_final\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"model_safe_final\")\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_resized_128/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/model_safe_final\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"model_safe_final\")\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification_unedited/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/model_safe_final\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"model_safe_final_2\")\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_resized_128/Test\"\n",
    "\n",
    "# import the model state\n",
    "imported_model_state_path = \"../storage/data/generated/model_safe_final\"   # test to 128x128 loss\n",
    "\n",
    "# load the model state into the model\n",
    "model_state_import_path = imported_model_state_path\n",
    "model.load_state_dict(torch.load(model_state_import_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"model_safe_final_2\")\n",
    "test_model(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def diffImage(image1, image2):\n",
    "    # Calculate the absolute difference between the two images\n",
    "    diff = np.abs(image1 - image2)\n",
    "    return diff\n",
    "\n",
    "def imageNumber(image1):\n",
    "    # Calculate the absolute difference between the two images\n",
    "    image_number = image1.sum()\n",
    "    return image_number\n",
    "\n",
    "def display_images(image1, image2):\n",
    "    # Calculate the absolute difference between the two images\n",
    "    diff = diffImage(image1,image2)\n",
    "   \n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    # Display image 1\n",
    "    axes[0].imshow(image1, cmap='gray')\n",
    "    axes[0].set_title(f'{imageNumber(image1)}')\n",
    "\n",
    "    # Display image 2\n",
    "    axes[1].imshow(image2, cmap='gray')\n",
    "    axes[1].set_title(f'{imageNumber(image2)}')\n",
    "\n",
    "    # Display the difference image\n",
    "    axes[2].imshow(diff, cmap='gray')\n",
    "    axes[2].set_title(f'{imageNumber(diff)}')\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def dataLoaderT(datasetPath):\n",
    "    # Load the test dataset\n",
    "    dataset_path = datasetPath\n",
    "    transform = T.Compose([\n",
    "        T.Resize((128, 128)),\n",
    "        T.ToTensor()])\n",
    "    dataset = ImageFolder(dataset_path, transform=transform)\n",
    "    test_dataloader = DataLoader(dataset, batch_size=120, shuffle=False)\n",
    "    return test_dataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_unedited = \"../storage/images/apple_disease_classification_unedited/Test\"\n",
    "dataset_path_resized = \"../storage/images/apple_resized_128/Test\"\n",
    "\n",
    "test_dataloader_unedited = dataLoaderT(dataset_path_unedited)\n",
    "test_dataloader_resized = dataLoaderT(dataset_path_resized)\n",
    "\n",
    "# Retrieve the first batch of data from the DataLoader\n",
    "data_unedited = next(iter(test_dataloader_unedited))\n",
    "data_resized = next(iter(test_dataloader_resized))\n",
    "\n",
    "random1 = np.random.randint(0, 120)\n",
    "random2 = np.random.randint(0, 120)\n",
    "unedited_image = data_unedited[0][random1]\n",
    "resized_image = data_resized[0][random1]\n",
    "\n",
    "# Convert the images to NumPy arrays\n",
    "unedited_image = unedited_image.permute(1, 2, 0).numpy()\n",
    "resized_image = resized_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display the images\n",
    "display_images(unedited_image, resized_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pink_lady-bMzUwwsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
