{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg imports toe als je ze nodig hebt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.io as tio\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from realtime_graph import realtimeplot\n",
    "import gc\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiyoonseij\u001b[0m (\u001b[33mteamnan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jiyoo\\workspace\\MakeAIWork3\\project3\\wandb\\run-20230531_143638-8bqm3ls9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamnan/MakeAIWork3/runs/8bqm3ls9' target=\"_blank\">neat-sky-5</a></strong> to <a href='https://wandb.ai/teamnan/MakeAIWork3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamnan/MakeAIWork3' target=\"_blank\">https://wandb.ai/teamnan/MakeAIWork3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamnan/MakeAIWork3/runs/8bqm3ls9' target=\"_blank\">https://wandb.ai/teamnan/MakeAIWork3/runs/8bqm3ls9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/teamnan/MakeAIWork3/runs/8bqm3ls9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1bfbaeb76d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize all the images in folder and subfolders ./apple_disease_classification/\n",
    "\n",
    "for subdir, dirs, files in os.walk('/apple_disease_classification/'):\n",
    "    for file in files:\n",
    "        filepath = subdir + os.sep + file\n",
    "\n",
    "        if filepath.endswith(\".jpg\") or filepath.endswith(\".jpeg\"): #to-do pre-check for all image filetypes\n",
    "            img = Image.open(filepath)\n",
    "            rgb_im = img.convert('RGB') #had to delete one because the jpg was not parseable somehow, blotch #17 is png ipv jpg look into it later\n",
    "            rgb_im_resized = rgb_im.resize((128,128))\n",
    "            rgb_im_resized.save(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = ToTensor()\n",
    "\n",
    "train_dataset_path = \"apple_disease_classification/Train\"\n",
    "train_dataset = ImageFolder(train_dataset_path, transform=transform)\n",
    "train_size = len(train_dataset_path)\n",
    "\n",
    "test_dataset_path = \"apple_disease_classification/Test\"\n",
    "test_dataset = ImageFolder(train_dataset_path, transform=transform)\n",
    "test_size = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blotch_Apple': 0, 'Normal_Apple': 1, 'Rot_Apple': 2, 'Scab_Apple': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2) #numworkers parallel/subprocesses\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False) #no need to shuffle when evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Because we inherit from Module base class\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB input, 6 filters, kernel of 5 x 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  #initialise convolution but not execute\n",
    "        \n",
    "        # Filter is 2 x 2 with a stride of 2 (defined once, used two times)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # in_channels = 6 because self.conv1 output has 6 channels\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Fully connected layer matched on output of conv2 layer\n",
    "        self.fc1 = nn.Linear(16 * 29 * 29, 120) # (64-5+1 = 60/2(pool) = 30-5+1 = 26/2 = 13)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # We have 10 labels\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "        # initialize dropout of 20%\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "    #-------------------------------------------------------\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution with relu layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # To match the output of the conv2 layer onto the first fully connected layer\n",
    "        # Like reshape() but makes no copy (reuses underlaying data)\n",
    "\n",
    "        #### RuntimeError: shape '[-1, 400]' is invalid for input of size 173056 (x.shape = torch.Size([64, 16, 13, 13]) )\n",
    "        #### print('x.shape after pool-relu-conv2:', x.shape) = x.shape after pool-relu-conv2: torch.Size([64, 16, 13, 13])\n",
    "\n",
    "        x = x.view(-1, 16 * 29 * 29)\n",
    "        # Transfer from convolution to classification part:\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # No activation on final layer \n",
    "        return self.fc3(x)\n",
    "\n",
    "#-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCNN = CNN().to(device)\n",
    "\n",
    "\n",
    "CrossEntropyLossCriterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(myCNN.parameters(),lr=0.01,momentum=0.9)\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = iter(trainloader)\n",
    "images, labels = next(train_iter)\n",
    "images[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train function\n",
    "from realtime_graph import realtimeplot\n",
    "import gc\n",
    "\n",
    "epochresults = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for idx, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape) = torch.Size([4, 3, 32, 32])\n",
    "\n",
    "        #---load data into GPU----\n",
    "        inputs = inputs.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        #-------------------------\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = myCNN.forward(inputs)\n",
    "        loss = CrossEntropyLossCriterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()  # reset previous calculated loss gradients to zero\n",
    "        loss.backward() # calculate new loss gradient\n",
    "\n",
    "        #memory management: free up space\n",
    "        del inputs, labels, outputs \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        optimizer.step() # update weights based on learning rate and gradients\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epochresults.append(epoch_loss)\n",
    "\n",
    "    realtimeplot(epochresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe from around epoch 35-40 overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the Validation images: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape) = torch.Size([4, 3, 32, 32])\n",
    "\n",
    "        #---load data into GPU----\n",
    "        inputs = inputs.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        #-------------------------\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = myCNN.forward (inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the Validation images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path_test = \"./apple_disease_classification/Test\"\n",
    "# transform = ToTensor()\n",
    "# dataset_test = ImageFolder(dataset_path, transform=transform)\n",
    "# dataset_test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# since we're not training, we don't need to calculate the gradients for our outputs\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset_test_loader):\n\u001b[0;32m      6\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m      7\u001b[0m         \u001b[39m# print(inputs.shape) = torch.Size([4, 3, 32, 32])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m         \u001b[39m#---load data into GPU----\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(dataset_test_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape) = torch.Size([4, 3, 32, 32])\n",
    "\n",
    "        #---load data into GPU----\n",
    "        inputs = inputs.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        #-------------------------\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = myCNN.forward (inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jiyoo/.cache\\torch\\hub\\pytorch_vision_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetmodel = torch.hub.load(\"pytorch/vision\", \"resnet18\", weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = resnetmodel.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 4\n",
    "resnetmodel.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "# Check if output size is correct\n",
    "resnetmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load to CUDA\n",
    "myresnetmodel = resnetmodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossEntropyLossCriterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(myresnetmodel.parameters(),lr=0.001,momentum=0.9)\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m epoch_loss \u001b[39m=\u001b[39m running_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(trainloader)\n\u001b[0;32m     37\u001b[0m epochresults\u001b[39m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m---> 39\u001b[0m realtimeplot(epochresults)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork3\\project3\\realtime_graph.py:15\u001b[0m, in \u001b[0;36mrealtimeplot\u001b[1;34m(inputlist)\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[39m.\u001b[39mplot(inputlist)\n\u001b[0;32m     14\u001b[0m plt\u001b[39m.\u001b[39mylim(ymin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m plt\u001b[39m.\u001b[39;49mshow(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     16\u001b[0m plt\u001b[39m.\u001b[39mpause(\u001b[39m.1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39mshow(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         display(\n\u001b[0;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure,\n\u001b[0;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39;49m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure)\n\u001b[0;32m     93\u001b[0m         )\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[0;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\IPython\\core\\formatters.py:177\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    175\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\IPython\\core\\formatters.py:221\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\IPython\\core\\formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[0;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(bytes_io, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\backend_bases.py:2346\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 2346\u001b[0m         bbox_inches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mget_tightbbox(\n\u001b[0;32m   2347\u001b[0m             renderer, bbox_extra_artists\u001b[39m=\u001b[39;49mbbox_extra_artists)\n\u001b[0;32m   2348\u001b[0m         \u001b[39mif\u001b[39;00m pad_inches \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2349\u001b[0m             pad_inches \u001b[39m=\u001b[39m rcParams[\u001b[39m'\u001b[39m\u001b[39msavefig.pad_inches\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\figure.py:1753\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1749\u001b[0m \u001b[39mif\u001b[39;00m ax\u001b[39m.\u001b[39mget_visible():\n\u001b[0;32m   1750\u001b[0m     \u001b[39m# some axes don't take the bbox_extra_artists kwarg so we\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[39m# need this conditional....\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m         bbox \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mget_tightbbox(\n\u001b[0;32m   1754\u001b[0m             renderer, bbox_extra_artists\u001b[39m=\u001b[39;49mbbox_extra_artists)\n\u001b[0;32m   1755\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1756\u001b[0m         bbox \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\axes\\_base.py:4388\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4386\u001b[0m         \u001b[39mif\u001b[39;00m ba:\n\u001b[0;32m   4387\u001b[0m             bb\u001b[39m.\u001b[39mappend(ba)\n\u001b[1;32m-> 4388\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_title_position(renderer)\n\u001b[0;32m   4389\u001b[0m axbbox \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   4390\u001b[0m bb\u001b[39m.\u001b[39mappend(axbbox)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\axes\\_base.py:2972\u001b[0m, in \u001b[0;36m_AxesBase._update_title_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2970\u001b[0m top \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(top, bb\u001b[39m.\u001b[39mymax)\n\u001b[0;32m   2971\u001b[0m \u001b[39mif\u001b[39;00m title\u001b[39m.\u001b[39mget_text():\n\u001b[1;32m-> 2972\u001b[0m     ax\u001b[39m.\u001b[39;49myaxis\u001b[39m.\u001b[39;49mget_tightbbox(renderer)  \u001b[39m# update offsetText\u001b[39;00m\n\u001b[0;32m   2973\u001b[0m     \u001b[39mif\u001b[39;00m ax\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39moffsetText\u001b[39m.\u001b[39mget_text():\n\u001b[0;32m   2974\u001b[0m         bb \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39moffsetText\u001b[39m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\axis.py:1323\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[1;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1323\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[0;32m   1325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_label_position(renderer)\n\u001b[0;32m   1327\u001b[0m \u001b[39m# go back to just this axis's tick labels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\axis.py:1270\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     tick\u001b[39m.\u001b[39mset_label1(label)\n\u001b[0;32m   1269\u001b[0m     tick\u001b[39m.\u001b[39mset_label2(label)\n\u001b[1;32m-> 1270\u001b[0m minor_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_minorticklocs()\n\u001b[0;32m   1271\u001b[0m minor_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminor\u001b[39m.\u001b[39mformatter\u001b[39m.\u001b[39mformat_ticks(minor_locs)\n\u001b[0;32m   1272\u001b[0m minor_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_minor_ticks(\u001b[39mlen\u001b[39m(minor_locs))\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\axis.py:1491\u001b[0m, in \u001b[0;36mAxis.get_minorticklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1489\u001b[0m minor_locs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminor\u001b[39m.\u001b[39mlocator())\n\u001b[0;32m   1490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_overlapping_locs:\n\u001b[1;32m-> 1491\u001b[0m     major_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajor\u001b[39m.\u001b[39;49mlocator()\n\u001b[0;32m   1492\u001b[0m     transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scale\u001b[39m.\u001b[39mget_transform()\n\u001b[0;32m   1493\u001b[0m     tr_minor_locs \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform(minor_locs)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\ticker.py:2136\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2135\u001b[0m     vmin, vmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_view_interval()\n\u001b[1;32m-> 2136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtick_values(vmin, vmax)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\ticker.py:2144\u001b[0m, in \u001b[0;36mMaxNLocator.tick_values\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2141\u001b[0m     vmin \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mvmax\n\u001b[0;32m   2142\u001b[0m vmin, vmax \u001b[39m=\u001b[39m mtransforms\u001b[39m.\u001b[39mnonsingular(\n\u001b[0;32m   2143\u001b[0m     vmin, vmax, expander\u001b[39m=\u001b[39m\u001b[39m1e-13\u001b[39m, tiny\u001b[39m=\u001b[39m\u001b[39m1e-14\u001b[39m)\n\u001b[1;32m-> 2144\u001b[0m locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_ticks(vmin, vmax)\n\u001b[0;32m   2146\u001b[0m prune \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prune\n\u001b[0;32m   2147\u001b[0m \u001b[39mif\u001b[39;00m prune \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\ticker.py:2083\u001b[0m, in \u001b[0;36mMaxNLocator._raw_ticks\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2081\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nbins \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   2082\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2083\u001b[0m         nbins \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49mget_tick_space(),\n\u001b[0;32m   2084\u001b[0m                         \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_n_ticks \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m9\u001b[39m)\n\u001b[0;32m   2085\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2086\u001b[0m         nbins \u001b[39m=\u001b[39m \u001b[39m9\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\axis.py:2734\u001b[0m, in \u001b[0;36mYAxis.get_tick_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_tick_space\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 2734\u001b[0m     ends \u001b[39m=\u001b[39m mtransforms\u001b[39m.\u001b[39;49mBbox\u001b[39m.\u001b[39;49munit()\u001b[39m.\u001b[39;49mtransformed(\n\u001b[0;32m   2735\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes\u001b[39m.\u001b[39;49mtransAxes \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi_scale_trans)\n\u001b[0;32m   2736\u001b[0m     length \u001b[39m=\u001b[39m ends\u001b[39m.\u001b[39mheight \u001b[39m*\u001b[39m \u001b[39m72\u001b[39m\n\u001b[0;32m   2737\u001b[0m     \u001b[39m# Having a spacing of at least 2 just looks good.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\transforms.py:479\u001b[0m, in \u001b[0;36mBboxBase.transformed\u001b[1;34m(self, transform)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[39mConstruct a `Bbox` by statically transforming this one by *transform*.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m pts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_points()\n\u001b[1;32m--> 479\u001b[0m ll, ul, lr \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(np\u001b[39m.\u001b[39;49marray(\n\u001b[0;32m    480\u001b[0m     [pts[\u001b[39m0\u001b[39;49m], [pts[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], pts[\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m]], [pts[\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m], pts[\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m]]]))\n\u001b[0;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m Bbox([ll, [lr[\u001b[39m0\u001b[39m], ul[\u001b[39m1\u001b[39m]]])\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\transforms.py:1490\u001b[0m, in \u001b[0;36mTransform.transform\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   1487\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dims))\n\u001b[0;32m   1489\u001b[0m \u001b[39m# Transform the values\u001b[39;00m\n\u001b[1;32m-> 1490\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_affine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_non_affine(values))\n\u001b[0;32m   1492\u001b[0m \u001b[39m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[39mif\u001b[39;00m ndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\transforms.py:2415\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[1;34m(self, points)\u001b[0m\n\u001b[0;32m   2413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_affine\u001b[39m(\u001b[39mself\u001b[39m, points):\n\u001b[0;32m   2414\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[1;32m-> 2415\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39mtransform(points)\n",
      "File \u001b[1;32mc:\\Users\\jiyoo\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\matplotlib\\transforms.py:2441\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_b\u001b[39m.\u001b[39mget_affine()\n\u001b[0;32m   2440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2441\u001b[0m     \u001b[39mreturn\u001b[39;00m Affine2D(np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix(),\n\u001b[0;32m   2442\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix()))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train function\n",
    "\n",
    "epochresults = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for idx, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape) = torch.Size([4, 3, 32, 32])\n",
    "\n",
    "        #---load data into GPU----\n",
    "        inputs = inputs.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        #-------------------------\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = myresnetmodel.forward(inputs)\n",
    "        loss = CrossEntropyLossCriterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()  # reset previous calculated loss gradients to zero\n",
    "        loss.backward() # calculate new loss gradient\n",
    "\n",
    "        #memory management: free up space\n",
    "        del inputs, labels, outputs \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        optimizer.step() # update weights based on learning rate and gradients\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epochresults.append(epoch_loss)\n",
    "\n",
    "    realtimeplot(epochresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(dataset_test_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs.shape) = torch.Size([4, 3, 32, 32])\n",
    "\n",
    "        #---load data into GPU----\n",
    "        inputs = inputs.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        #-------------------------\n",
    "        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = myresnetmodel.forward (inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
