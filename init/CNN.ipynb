{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Net (CNN)\n",
    "to detect apples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cosmos_functions as cf\n",
    "\n",
    "import pprint\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as FF\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "import wandb\n",
    "from init.config import *\n",
    "from datetime import datetime\n",
    "from os import listdir, path\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = userAccountID \n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "x = torch.ones(1, device=device)\n",
    "\n",
    "print(f\"Device is '{device}' Thus a tensor will look like this: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show an image from the dataloader with its label\n",
    "def show_batch(train_d,test_d,val_d):\n",
    "    # Get a batch of data from the DataLoader\n",
    "    data_train = next(iter(train_d))\n",
    "    data_test = next(iter(test_d))\n",
    "    data_val = next(iter(val_d))\n",
    "\n",
    "    # Set the savefig.bbox parameter to 'tight'\n",
    "    plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "    # Retrieve the first tensor and its corresponding label\n",
    "    image_train = data_train[0][0]\n",
    "    image_test = data_test[0][0]\n",
    "    image_val = data_val[0][0]\n",
    "    label_train = data_train[1][0]\n",
    "    label_test = data_test[1][0]\n",
    "    label_val = data_val[1][0]\n",
    "  \n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "\n",
    "    # Convert the image tensor to a NumPy array and transpose the dimensions\n",
    "    np_image_train = image_train.permute(1, 2, 0).numpy()\n",
    "    np_image_test = image_test.permute(1, 2, 0).numpy()\n",
    "    np_image_val = image_val.permute(1, 2, 0).numpy()\n",
    "    \n",
    "\n",
    "        # Display the original image in the first subplot\n",
    "    axes[0].imshow(np_image_train)  # ,cmap='gray' after the image name to create a greyscale image.\n",
    "    axes[0].set_title(f'{label_train}, {image_train.shape}')\n",
    "\n",
    "    # Display the pooled image in the second subplot\n",
    "    axes[1].imshow(np_image_test)  # ,cmap='gray' after the image name to create a greyscale image.\n",
    "    axes[1].set_title(f'{label_test}, {image_test.shape}')\n",
    "\n",
    "    # Display the pooled image in the third subplot\n",
    "    axes[2].imshow(np_image_val)  # ,cmap='gray' after the image name to create a greyscale image.\n",
    "    axes[2].set_title(f'{label_val}, {image_val.shape}')\n",
    "\n",
    "    # Adjust spacing between subplots to prevent overlap\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine accuracy \n",
    "\n",
    "def evaluate_accuracy(logits, y_true):\n",
    "    # get index with the largest logit value PER OBSERVATION\n",
    "    _, y_pred = torch.max(logits, dim=1)\n",
    "\n",
    "    # calculate proportion of correct prediction\n",
    "    correct_pred = (y_pred == y_true).float()  # PyCharm error Unresolved attribute reference 'float' for class 'bool'\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    return acc * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, n_epochs, model_file_name='model.pt'):\n",
    "    # initialize container variable for model performance results per epoch\n",
    "    history = {\n",
    "        'n_epochs': n_epochs,\n",
    "        'loss': {\n",
    "            'train': [],\n",
    "            'val': []\n",
    "        },\n",
    "        'acc': {\n",
    "            'train': [],\n",
    "            'val': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    val_loss_min = np.Inf\n",
    "\n",
    "    # loop per epoch\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        # initialize tracker for training performance\n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "\n",
    "        # prepare model for training\n",
    "        model.train()\n",
    "\n",
    "        # loop for each batch\n",
    "        for data, target in tqdm(train_loader):\n",
    "            # move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # STEP 1: clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # STEP 2: forward pass\n",
    "            output = model(data)\n",
    "            # STEP 3: calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # STEP 4: backward pass\n",
    "            loss.backward()\n",
    "            # STEP 5: perform parameter update\n",
    "            optimizer.step()\n",
    "            # STEP 6: accumulate training loss and accuracy\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            acc = evaluate_accuracy(output, target)\n",
    "            train_acc += acc.item() * data.size(0)\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        # disable gradient calculation\n",
    "        with torch.no_grad():\n",
    "            # initialize tracker for validation performance\n",
    "            val_acc = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            # prepare model for evaluation\n",
    "            model.eval()\n",
    "\n",
    "            # loop for each batch\n",
    "            for data, target in tqdm(val_loader):\n",
    "                # move data to device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # STEP 1: forward pass\n",
    "                output = model(data)\n",
    "                # STEP 2: calculate the loss\n",
    "                loss = criterion(output, target)\n",
    "                # STEP 3: accumulate validation loss and accuracy\n",
    "                val_loss += loss.item() * data.size(0)\n",
    "                acc = evaluate_accuracy(output, target)\n",
    "                val_acc += acc.item() * data.size(0)\n",
    "\n",
    "        ####################\n",
    "        # model evaluation #\n",
    "        ####################\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss /= len(train_loader.sampler)\n",
    "        val_loss /= len(val_loader.sampler)\n",
    "        history['loss']['train'].append(train_loss)\n",
    "        history['loss']['val'].append(val_loss)\n",
    "\n",
    "        # calculate average accuracy over an epoch\n",
    "        train_acc /= len(train_loader.sampler)\n",
    "        val_acc /= len(val_loader.sampler)\n",
    "        history['acc']['train'].append(train_acc)\n",
    "        history['acc']['val'].append(val_acc)\n",
    "\n",
    "        # print training progress per epoch\n",
    "        print(f'Epoch {epoch+1:03} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.2f} | Val Acc: {val_acc:.2f}')\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if val_loss <= val_loss_min:\n",
    "            print(\n",
    "                f'Validation loss decreased ({val_loss_min:.5f} --> {val_loss:.5f})  Saving model to {model_file_name}...')\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            val_loss_min = val_loss\n",
    "\n",
    "        print()\n",
    "\n",
    "    # return model performance history\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset_path = \"build/Practicum/pics/2750\"\n",
    "transform = T.ToTensor()\n",
    "dataset = ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "dataset.class_to_idx\n",
    "pp = pprint.PrettyPrinter(indent=1)  # Create a PrettyPrinter instance with an indentation of 1 space\n",
    "pp.pprint(dataset.class_to_idx)  # Use the pprint method to print the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test, train and validation set and the dataloader\n",
    "\n",
    "# setup split data \n",
    "dataset_size = len(dataset)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "\n",
    "# Set the seed for the generator\n",
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "\n",
    "# Define the batch size for the DataLoader\n",
    "batch_size = 128\n",
    "\n",
    "# Create the DataLoader to load the dataset in batches\n",
    "train_d = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_d = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_d = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Show the 1st img in the dataset\n",
    "show_batch(train_d, test_d,val_d)\n",
    "print(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    def __init__(self, dropout=0):\n",
    "        self.dropout = dropout\n",
    "        \n",
    "\n",
    "        # Because we inherit from Module base class\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB input, 6 filters, kernel of 5 x 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "        # Filter is 2 x 2 with a stride of 2 (defined once, used two times)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # in_channels = 6 because self.conv1 output has 6 channels\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Fully connected layer matched on output of conv2 layer\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)\n",
    "        \n",
    "        # Dropout layer1\n",
    "        self.dropout1 = nn.Dropout(self.dropout)    \n",
    "\n",
    "        # Dropout layer2\n",
    "        self.dropout2 = nn.Dropout(self.dropout)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # We only have 2 labels\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    #-------------------------------------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution with relu layers\n",
    "        x = self.pool(FF.relu(self.conv1(x)))\n",
    "        x = self.pool(FF.relu(self.conv2(x)))\n",
    "        \n",
    "        # To match the output of the conv2 layer onto the first fully connected layer\n",
    "        # Like reshape() but makes no copy (reuses underlaying data)\n",
    "        x = x.view(-1, 16 * 13 * 13)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = FF.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = FF.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # No activation on final layer \n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparameters and the model\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1\n",
    "momentum = 0.9\n",
    "total_epochs =0\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "# model parameters\n",
    "\n",
    "model = CNN(dropout=dropout) # Create the model\n",
    "model.to(device) # set model to device\n",
    "model.train() # set model to train mode\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()   # Define the loss function  \n",
    " \n",
    " # set the loaders to the correct names for the training loop\n",
    "train_loader = train_d\n",
    "val_loader = val_d\n",
    "\n",
    "# set epochloss to empty list\n",
    "epoch_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionairies for the hyperparameters and model parameters\n",
    "hyperparameters = { 'learning_rate' : learning_rate, 'epochs' : epochs, 'momentum' : momentum, 'dropout' : dropout}\n",
    "model_parameters = { 'model' : 'cnn', 'optimizer' : 'SGD', 'criterion' : 'CrossEntropyLoss'}  # 'model' : model, 'optimizer' : optimizer, 'criterion' : criterion\n",
    "parameters = {**hyperparameters, **model_parameters}    # merge the two dictionairies\n",
    "pp = pprint.PrettyPrinter(indent=1)  \n",
    "\n",
    "pp.pprint(f'hyperparameters: {hyperparameters}')\n",
    "print()\n",
    "pp.pprint(f'model_parameters: {model_parameters}')\n",
    "print()\n",
    "pp.pprint(f'parameters: {parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training loop\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "saveFileName = f'{timestamp}_{userAccountID}.pt'\n",
    "\n",
    "history = train(\n",
    "    model, train_loader, val_loader, criterion, optimizer, n_epochs=epochs,\n",
    "    model_file_name=saveFileName\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the data to azure cosmos NoSQL database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document = {'id': unique_id, 'pth_data': pth_bytes, 'hyperparameters': hyperparameters, 'model_parameters': model_parameters}\n",
    "cf.save_data(saveFileName, parameters, history)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "\n",
    "from azure.cosmos import CosmosClient\n",
    "import base64\n",
    "\n",
    "import torch\n",
    "\n",
    "# Retrieve settings from the config file\n",
    "endpoint_uri = settings['host']\n",
    "auth_key = settings['master_key']\n",
    "database_name = settings['database_id']\n",
    "container_name = settings['container_id']\n",
    "\n",
    "# Create the Cosmos DB client\n",
    "client = CosmosClient(endpoint_uri, auth_key)\n",
    "\n",
    "# Get the database and container\n",
    "database = client.get_database_client(database_name)\n",
    "container = database.get_container_client(container_name)\n",
    "\n",
    "# Retrieve the document containing the .pth data (assuming you know the unique_id)\n",
    "unique_id = \"20230602_0010_dyrr\"\n",
    "item = container.read_item(item=unique_id, partition_key=unique_id)\n",
    "\n",
    "# Retrieve the pth_data from the item\n",
    "pth_bytes = item['pth_data']\n",
    "\n",
    "# Specify the path to save the .pth file\n",
    "pth_file_path = f'/Users/stephandekker/workspace/pink_lady/noSQL/pth/imported/{unique_id}.pth'\n",
    "\n",
    "# Decode and save the .pth data to a file\n",
    "decoded_pth_data = base64.b64decode(pth_bytes)\n",
    "with open(pth_file_path, 'wb') as file:\n",
    "    file.write(decoded_pth_data)\n",
    "\n",
    "# Retrieve the hyperparameters\n",
    "hyperparameters = item['hyperparameters']\n",
    "\n",
    "# Save the variable as a .pth file\n",
    "torch.save(decoded_pth_data, pth_file_path)\n",
    "\n",
    "# # print the hyperparameters\n",
    "# print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = test_d\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "y_test = []\n",
    "y_pred = []\n",
    "counter = 0\n",
    "# disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # prepare model for evaluation\n",
    "    model.eval()\n",
    "\n",
    "    # loop for each data\n",
    "    for data, target in tqdm(test_loader):\n",
    "        # move data to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        counter += 1\n",
    "        # STEP 1: forward pass\n",
    "        output = model(data)\n",
    "        # STEP 2: get predicted label\n",
    "        _, label = torch.max(output, dim=1)\n",
    "        # STEP 3: append actual and predicted label\n",
    "        y_test += target.cpu().numpy().tolist()  # set to cpu and convert to list for old visualisation\n",
    "        y_pred += label.cpu().numpy().tolist()\n",
    "        print(counter)\n",
    "\n",
    "print(f'End{counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n",
    "ax.set_xlabel(\"Predicted Label\")\n",
    "ax.set_ylabel(\"Actual Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pink_lady-bMzUwwsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
