{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import modules.cosmos_functions as cf\n",
    "import numpy as np\n",
    "import pprint\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to display images\n",
    "def reverse_normalize(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    image = image.clone()\n",
    "    for i in range(3):\n",
    "        image[i] = (image[i] * std[i]) + mean[i]\n",
    "    return image\n",
    "\n",
    "def show_batch(test_d):\n",
    "    # Get the first batch of data from the DataLoader\n",
    "    data_test = next(iter(test_d))\n",
    "\n",
    "    # Retrieve the first tensor and its corresponding label\n",
    "    image_test = data_test[0][0]\n",
    "    label_test = data_test[1][0]\n",
    "\n",
    "    # Reverse the normalization of the image\n",
    "    image_test = reverse_normalize(image_test)\n",
    "\n",
    "    # Convert the image tensor to a NumPy array and transpose the dimensions\n",
    "    np_image_test = image_test.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(np_image_test)\n",
    "    plt.title(f'{label_test}, {image_test.shape}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is 'mps' Thus a tensor will look like this: tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# set the device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "x = torch.ones(1, device=device)\n",
    "\n",
    "print(f\"Device is '{device}' Thus a tensor will look like this: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephandekker/.local/share/virtualenvs/pink_lady-bMzUwwsu/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/stephandekker/.local/share/virtualenvs/pink_lady-bMzUwwsu/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# add the resnet18 model for testing the test dataset with the trained model\n",
    "# import the resnet18 model\n",
    "from torchvision import models\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# freeze the model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# change the last layer of the model to fit the number of classes in the dataset\n",
    "model.fc = nn.Linear(512, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        \n",
    "        # Calculate the output size after pooling and convolutions\n",
    "        self.fc_input_size = 16 * 53 * 53  # Adjusted for input size 224x224\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 120)\n",
    "        self.dropout1 = nn.Dropout(self.dropout)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.dropout2 = nn.Dropout(self.dropout)\n",
    "        self.fc3 = nn.Linear(84,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, self.fc_input_size)  # Flatten the output of the conv layer automatically\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = F.softmax(self.fc3(x), dim=1)  # softmax on dim 1 to get probabilities for apple\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the 1st img in the dataset\n",
    "# show_batch(test_d)\n",
    "# print(test_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../storage/data/generated/20230608-100518_pinky_acc.pt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_model_path = \"../storage/data/generated/20230608-100518_pinky_acc.pt\"   # test to test 224x224\n",
    "# imported_model_path = \"../storage/data/generated/20230605-134750_pinky_acc.pt\"  # high accuracy\n",
    "# imported_model_path = cf.load_pth('20230605_160852_pinky')  # issues; WIP\n",
    "imported_model_path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.5333\n",
      "Normal Apple accuracy: 0.9583\n",
      "Abnormal Apple accuracy: 0.4271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the model\n",
    "# model = CNN()\n",
    "model_import_path = imported_model_path\n",
    "model.load_state_dict(torch.load(model_import_path))\n",
    "model.to(device)\n",
    "\n",
    "# Load the test dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification/Test\"\n",
    "\n",
    "# Define the label dictionary\n",
    "labels_dict = {\n",
    "    'Blotch_Apple': 0,\n",
    "    'Normal_Apple': 1,\n",
    "    'Rot_Apple': 2,\n",
    "    'Scab_Apple': 3\n",
    "}\n",
    "\n",
    "def test_model(model, datasetPath):\n",
    "    model.eval()    \n",
    "\n",
    "    # Load the test dataset\n",
    "    dataset_path = datasetPath\n",
    "    transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    dataset = ImageFolder(dataset_path, transform=transform)\n",
    "    test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    labels_dict = dataset.class_to_idx\n",
    "\n",
    "    # Track the overall test accuracy and accuracy by each type of apple\n",
    "    overall_correct = 0\n",
    "    overall_total = 0\n",
    "    normal_correct = 0\n",
    "    normal_total = 0\n",
    "    abnormal_correct = 0\n",
    "    abnormal_total = 0\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update accuracy counts\n",
    "        overall_correct += (predicted == labels).sum().item()\n",
    "        overall_total += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy for normal apples vs. abnormal apples\n",
    "        normal_mask = labels == labels_dict['Normal_Apple']\n",
    "        abnormal_mask = ~normal_mask\n",
    "        normal_correct += (predicted[normal_mask] == labels[normal_mask]).sum().item()\n",
    "        normal_total += normal_mask.sum().item()\n",
    "        abnormal_correct += (predicted[abnormal_mask] == labels[abnormal_mask]).sum().item()\n",
    "        abnormal_total += abnormal_mask.sum().item()\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = overall_correct / overall_total\n",
    "\n",
    "    # Calculate accuracy for normal apples and abnormal apples separately\n",
    "    normal_accuracy = normal_correct / normal_total if normal_total != 0 else 0.0\n",
    "    abnormal_accuracy = abnormal_correct / abnormal_total if abnormal_total != 0 else 0.0\n",
    "\n",
    "    # Print overall accuracy\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # Print accuracy for normal apples and abnormal apples separately\n",
    "    print(f\"Normal Apple accuracy: {normal_accuracy:.4f}\")\n",
    "    print(f\"Abnormal Apple accuracy: {abnormal_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "test_model(model, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.5333\n",
      "Normal Apple accuracy: 0.9583\n",
      "Abnormal Apple accuracy: 0.4271\n",
      "\n",
      "{'Blotch_Apple': 0, 'Normal_Apple': 1, 'Rot_Apple': 2, 'Scab_Apple': 3}\n",
      "Confusion Matrix:\n",
      "[[11  8  1 10]\n",
      " [ 0 23  0  1]\n",
      " [ 0 21 11  6]\n",
      " [ 0  9  0 19]]\n"
     ]
    }
   ],
   "source": [
    "# ... code for loading the model and test dataset ...\n",
    "\n",
    "def test_model(model, datasetPath):\n",
    "    model.eval()    \n",
    "\n",
    "    # Load the test dataset\n",
    "    dataset_path = datasetPath\n",
    "    transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    dataset = ImageFolder(dataset_path, transform=transform)\n",
    "    test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    labels_dict = dataset.class_to_idx\n",
    "\n",
    "    # Track the overall test accuracy and accuracy by each type of apple\n",
    "    overall_correct = 0\n",
    "    overall_total = 0\n",
    "    normal_correct = 0\n",
    "    normal_total = 0\n",
    "    abnormal_correct = 0\n",
    "    abnormal_total = 0\n",
    "\n",
    "    # Initialize the confusion matrix\n",
    "    num_classes = len(labels_dict)\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update accuracy counts\n",
    "        overall_correct += (predicted == labels).sum().item()\n",
    "        overall_total += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy for normal apples vs. abnormal apples\n",
    "        normal_mask = labels == labels_dict['Normal_Apple']\n",
    "        abnormal_mask = ~normal_mask\n",
    "        normal_correct += (predicted[normal_mask] == labels[normal_mask]).sum().item()\n",
    "        normal_total += normal_mask.sum().item()\n",
    "        abnormal_correct += (predicted[abnormal_mask] == labels[abnormal_mask]).sum().item()\n",
    "        abnormal_total += abnormal_mask.sum().item()\n",
    "\n",
    "        # Update the confusion matrix\n",
    "        for true_label, predicted_label in zip(labels.cpu().numpy(), predicted.cpu().numpy()):\n",
    "            confusion_matrix[true_label][predicted_label] += 1\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = overall_correct / overall_total\n",
    "\n",
    "    # Calculate accuracy for normal apples and abnormal apples separately\n",
    "    normal_accuracy = normal_correct / normal_total if normal_total != 0 else 0.0\n",
    "    abnormal_accuracy = abnormal_correct / abnormal_total if abnormal_total != 0 else 0.0\n",
    "\n",
    "    # Print overall accuracy\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # Print accuracy for normal apples and abnormal apples separately\n",
    "    print(f\"Normal Apple accuracy: {normal_accuracy:.4f}\")\n",
    "    print(f\"Abnormal Apple accuracy: {abnormal_accuracy:.4f}\")\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print()\n",
    "    print(labels_dict)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "test_model(model, dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'class_to_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(test_dataloader\u001b[39m.\u001b[39;49mclass_to_idx)\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(labels_dict)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'class_to_idx'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_dataloader.class_to_idx)\n",
    "# print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.5333\n",
      "Normal Apple accuracy: 0.9583\n",
      "Abnormal Apple accuracy: 0.4271\n",
      "Confusion Matrix:\n",
      "True Labels \\ Predicted Labels:\t0 (Blotch_Apple)\t1 (Normal_Apple)\t2 (Rot_Apple)\t3 (Scab_Apple)\t\n",
      "0 (Blotch_Apple):\t11\t8\t1\t10\t\n",
      "1 (Normal_Apple):\t0\t23\t0\t1\t\n",
      "2 (Rot_Apple):\t0\t21\t11\t6\t\n",
      "3 (Scab_Apple):\t0\t9\t0\t19\t\n"
     ]
    }
   ],
   "source": [
    "# ... code for loading the model and test dataset ...\n",
    "\n",
    "# Define the label dictionary\n",
    "labels_dict = {\n",
    "    'Blotch_Apple': 0,\n",
    "    'Normal_Apple': 1,\n",
    "    'Rot_Apple': 2,\n",
    "    'Scab_Apple': 3\n",
    "}\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    # Track the overall test accuracy and accuracy by each type of apple\n",
    "    overall_correct = 0\n",
    "    overall_total = 0\n",
    "    normal_correct = 0\n",
    "    normal_total = 0\n",
    "    abnormal_correct = 0\n",
    "    abnormal_total = 0\n",
    "\n",
    "    # Initialize the confusion matrix\n",
    "    num_classes = len(labels_dict)\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update accuracy counts\n",
    "        overall_correct += (predicted == labels).sum().item()\n",
    "        overall_total += labels.size(0)\n",
    "\n",
    "        # Calculate accuracy for normal apples vs. abnormal apples\n",
    "        normal_mask = labels == labels_dict['Normal_Apple']\n",
    "        abnormal_mask = ~normal_mask\n",
    "        normal_correct += (predicted[normal_mask] == labels[normal_mask]).sum().item()\n",
    "        normal_total += normal_mask.sum().item()\n",
    "        abnormal_correct += (predicted[abnormal_mask] == labels[abnormal_mask]).sum().item()\n",
    "        abnormal_total += abnormal_mask.sum().item()\n",
    "\n",
    "        # Update the confusion matrix\n",
    "        for true_label, predicted_label in zip(labels.cpu().numpy(), predicted.cpu().numpy()):\n",
    "            confusion_matrix[true_label][predicted_label] += 1\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = overall_correct / overall_total\n",
    "\n",
    "    # Calculate accuracy for normal apples and abnormal apples separately\n",
    "    normal_accuracy = normal_correct / normal_total if normal_total != 0 else 0.0\n",
    "    abnormal_accuracy = abnormal_correct / abnormal_total if abnormal_total != 0 else 0.0\n",
    "\n",
    "    # Print overall accuracy\n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # Print accuracy for normal apples and abnormal apples separately\n",
    "    print(f\"Normal Apple accuracy: {normal_accuracy:.4f}\")\n",
    "    print(f\"Abnormal Apple accuracy: {abnormal_accuracy:.4f}\")\n",
    "\n",
    "    # Print the confusion matrix with labels\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Labels \\\\ Predicted Labels:\", end=\"\\t\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"{i} ({list(labels_dict.keys())[i]})\", end=\"\\t\")\n",
    "    print()\n",
    "    for i in range(num_classes):\n",
    "        print(f\"{i} ({list(labels_dict.keys())[i]}):\", end=\"\\t\")\n",
    "        for j in range(num_classes):\n",
    "            print(confusion_matrix[i][j], end=\"\\t\")\n",
    "        print()\n",
    "\n",
    "test_model(model, test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pink_lady-bMzUwwsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
