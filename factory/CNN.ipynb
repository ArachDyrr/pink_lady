{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Net (CNN)\n",
    "to detect apples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import modules.cosmos_functions as cf\n",
    "\n",
    "import pprint\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "from os import listdir, path\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "x = torch.ones(1, device=device)\n",
    "\n",
    "print(f\"Device is '{device}' Thus a tensor will look like this: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show the images\n",
    "\n",
    "\n",
    "def reverse_normalize(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    image = image.clone()\n",
    "    for i in range(3):\n",
    "        image[i] = (image[i] * std[i]) + mean[i]\n",
    "    return image\n",
    "\n",
    "def show_batch(train_d, val_d):\n",
    "    # Get a batch of data from the DataLoader\n",
    "    data_train = next(iter(train_d))\n",
    "    data_val = next(iter(val_d))\n",
    "\n",
    "    # Set the savefig.bbox parameter to 'tight'\n",
    "    plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "    # Retrieve the first tensor and its corresponding label\n",
    "    image_train = data_train[0][0]\n",
    "    # image_test = data_test[0][0]\n",
    "    image_val = data_val[0][0]\n",
    "    label_train = data_train[1][0]\n",
    "    # label_test = data_test[1][0]\n",
    "    label_val = data_val[1][0]\n",
    "\n",
    "    # Reverse the normalization of the images\n",
    "    image_train = reverse_normalize(image_train)\n",
    "    # image_test = reverse_normalize(image_test)\n",
    "    image_val = reverse_normalize(image_val)\n",
    "\n",
    "    # Convert the image tensors to NumPy arrays and transpose the dimensions\n",
    "    np_image_train = image_train.permute(1, 2, 0).numpy()\n",
    "    # np_image_test = image_test.permute(1, 2, 0).numpy()\n",
    "    np_image_val = image_val.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "    # Display the image in the first subplot\n",
    "    axes[0].imshow(np_image_train)\n",
    "    axes[0].set_title(f'{label_train}, {image_train.shape}')\n",
    "\n",
    "    # Display the image in the third subplot\n",
    "    axes[1].imshow(np_image_val)\n",
    "    axes[1].set_title(f'{label_val}, {image_val.shape}')\n",
    "\n",
    "    # # Display the image in the second subplot\n",
    "    # axes[2].imshow(np_image_test)\n",
    "    # axes[2].set_title(f'{label_test}, {image_test.shape}')\n",
    "\n",
    "    # Adjust spacing between subplots to prevent overlap\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine accuracy \n",
    "\n",
    "def evaluate_accuracy(logits, y_true):\n",
    "    # get index with the largest logit value PER OBSERVATION\n",
    "    _, y_pred = torch.max(logits, dim=1)\n",
    "\n",
    "    # calculate proportion of correct prediction\n",
    "    correct_pred = (y_pred == y_true).float()  # PyCharm error Unresolved attribute reference 'float' for class 'bool'\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    return acc * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, n_epochs, model_file_name='model.pt',local_save_path='storage/data/generated'):\n",
    "    # initialize container variable for model performance results per epoch\n",
    "    history = {\n",
    "        'n_epochs': n_epochs,\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }   \n",
    "\n",
    "    # initialize tracker for minimum validation loss and maxiumum validation accuracy\n",
    "    val_loss_min = np.Inf\n",
    "    val_loss_epoch = 0\n",
    "    val_acc_max = 0.0\n",
    "    val_acc_epoch = 0\n",
    "    best_results = {\n",
    "        'val_loss_min': val_loss_min,\n",
    "        'val_loss_epoch': val_loss_epoch,\n",
    "        'val_acc_max': val_acc_max,\n",
    "        'val_acc_epoch': val_acc_epoch\n",
    "        }    \n",
    "\n",
    "    model_file_name_loss = f'{str(model_file_name[:-3])}_loss.pt'\n",
    "    model_file_name_acc = f'{str(model_file_name[:-3])}_acc.pt'\n",
    "    final_model_file_name = f'{str(model_file_name[:-3])}_final.pt'\n",
    "    locally_saved_path = local_save_path   \n",
    "\n",
    "    file_data = { \n",
    "                'local_save_path' : locally_saved_path,\n",
    "                'min_loss_file' : model_file_name_loss,\n",
    "                'max_acc_file' : model_file_name_acc,\n",
    "                'final_epoch_file' : final_model_file_name\n",
    "                  }\n",
    "    \n",
    "    model_safe_loss = f'../{locally_saved_path}/{model_file_name_loss}'\n",
    "    model_safe_acc = f'../{locally_saved_path}/{model_file_name_acc}'\n",
    "    model_safe_final = f'../{locally_saved_path}/{final_model_file_name}'\n",
    "\n",
    "    # loop per epoch\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        \n",
    "        # initialize tracker for training performance\n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "\n",
    "        # prepare model for training\n",
    "        model.train()\n",
    "\n",
    "        # loop for each batch\n",
    "        for data, target in train_loader:\n",
    "            # move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # STEP 1: clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # STEP 2: forward pass\n",
    "            output = model(data)\n",
    "            # STEP 3: calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # STEP 4: backward pass\n",
    "            loss.backward()\n",
    "            # STEP 5: perform parameter update\n",
    "            optimizer.step()\n",
    "            # STEP 6: accumulate training loss and accuracy\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            acc = evaluate_accuracy(output, target)\n",
    "            train_acc += acc.item() * data.size(0)\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        # disable gradient calculation\n",
    "        with torch.no_grad():\n",
    "            # initialize tracker for validation performance\n",
    "            val_acc = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            # prepare model for evaluation\n",
    "            model.eval()\n",
    "\n",
    "            # loop for each batch\n",
    "            for data, target in val_loader:\n",
    "                # move data to device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # STEP 1: forward pass\n",
    "                output = model(data)\n",
    "                # STEP 2: calculate the loss\n",
    "                loss = criterion(output, target)\n",
    "                # STEP 3: accumulate validation loss and accuracy\n",
    "                val_loss += loss.item() * data.size(0)\n",
    "                acc = evaluate_accuracy(output, target)\n",
    "                val_acc += acc.item() * data.size(0)\n",
    "\n",
    "\n",
    "        ####################\n",
    "        # model evaluation #\n",
    "        ####################\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss /= len(train_loader.sampler)\n",
    "        val_loss /= len(val_loader.sampler)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        # calculate average accuracy over an epoch\n",
    "        train_acc /= len(train_loader.sampler)\n",
    "        val_acc /= len(val_loader.sampler)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        # print training progress per epoch\n",
    "        print(f'Epoch {epoch+1:03} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.2f} | Val Acc: {val_acc:.2f}')\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if val_loss <= val_loss_min:\n",
    "            print(\n",
    "                f'Validation loss decreased ({val_loss_min:.5f} --> {val_loss:.5f})  Saving model to {model_file_name}...')\n",
    "            \n",
    "\n",
    "            torch.save(model.state_dict(), model_safe_loss)\n",
    "            val_loss_min = val_loss\n",
    "            best_results['val_loss_min'] = val_loss_min\n",
    "            best_results['val_loss_epoch'] = epoch+1\n",
    "        \n",
    "        # save model if validation accuracy has decreased\n",
    "        if val_acc >= val_acc_max:\n",
    "            print(\n",
    "                f'Validation accuracy increased ({val_acc_max:.5f} --> {val_acc:.5f})  Saving model to {model_file_name}...')\n",
    "              \n",
    "            torch.save(model.state_dict(), model_safe_acc)\n",
    "            val_acc_max = val_acc\n",
    "            best_results['val_acc_max'] = val_acc_max\n",
    "            best_results['val_acc_epoch'] = epoch+1\n",
    "\n",
    "        # log metrics to wandb\n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \"train_acc\": train_acc, \"val_acc\": val_acc})\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(), model_safe_final)\n",
    "\n",
    "    results = best_results, history, file_data\n",
    "    \n",
    "    # return model performance history\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset_path = \"../storage/images/apple_cropped\"\n",
    "# transform and normalize the data\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    # T.transforms.Resize((256, 256)),\n",
    "    # T.transforms.RandomCrop((224, 224)),\n",
    "    T.transforms.RandomHorizontalFlip(),\n",
    "    T.transforms.RandomVerticalFlip(),\n",
    "    T.transforms.RandomRotation(25),  # Randomly rotate the image by a maximum of 30 degrees\n",
    "    T.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Slightly change the image color\n",
    "    T.transforms.RandomGrayscale(p=0.1),  # Randomly convert the image to grayscale with a probability of 10%\n",
    "    T.transforms.RandomErasing(p=0.1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),  # Randomly erase rectangular patches of the image with a probability of 10%\n",
    "    # T.transforms.RandomPerspective(distortion_scale=0.2, p=0.1, interpolation=3),  # Randomly apply a perspective transformation to the image with a probability of 10%\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "dataset.class_to_idx\n",
    "pp = pprint.PrettyPrinter(indent=1)  # Create a PrettyPrinter instance with an indentation of 1 space\n",
    "pp.pprint(dataset.class_to_idx)  # Use the pprint method to print the dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test, train and validation set and the dataloader\n",
    "\n",
    "# setup split data \n",
    "dataset_size = len(dataset)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.3\n",
    "\n",
    "\n",
    "\n",
    "# Set the seed for the generator\n",
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = dataset_size - train_size \n",
    "\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "\n",
    "# Define the batch size for the DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader to load the dataset in batches\n",
    "train_d = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2,)\n",
    "val_d = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# print the shape of the 1st image in the dataset\n",
    "print(train_dataset[0][0].shape)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "# Show the 1st img in the dataset\n",
    "show_batch(train_d, val_d)\n",
    "print(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this model is so bad!\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CNNModel, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(3, 9, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.fc = nn.Linear(9 * 112 * 112, num_classes)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.pool(x)\n",
    "        \n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# # Create an instance of the CNN model\n",
    "# model = CNNModel(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0):\n",
    "        super(CNN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        \n",
    "        # Calculate the output size after pooling and convolutions\n",
    "        self.fc_input_size = 16 * 53 * 53  # Adjusted for input size 224x224\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 120)\n",
    "        self.dropout1 = nn.Dropout(self.dropout)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.dropout2 = nn.Dropout(self.dropout)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, self.fc_input_size)  # Flatten the output of the conv layer automatically\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = F.softmax(self.fc3(x), dim=1)  # softmax on dim 1 to get probabilities for apple\n",
    "        \n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparameters and the model\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "betas = None  # (0.9, 0.999)\n",
    "momentum = 0.9\n",
    "dropout = 0.3\n",
    "total_epochs = 0  # legacy code\n",
    "\n",
    "# model parameters\n",
    "\n",
    "model = CNN(dropout=dropout) # Create the model\n",
    "model.to(device) # set model to device\n",
    "model.train() # set model to train mode\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=betas)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()   # Define the loss function  \n",
    " \n",
    " # set the loaders to the correct names for the training loop\n",
    "train_loader = train_d\n",
    "val_loader = val_d\n",
    "\n",
    "# set epochloss to empty list\n",
    "epoch_loss = []\n",
    "# create dictionairies for the hyperparameters and model parameters\n",
    "hyperparameters = { 'learning_rate' : learning_rate, 'epochs' : epochs, 'momentum' : momentum, 'betas' : betas, 'dropout' : dropout}\n",
    "model_parameters = { 'model' : 'cnn', 'optimizer' : 'SGD', 'criterion' : 'CrossEntropyLoss'}  # 'model' : model, 'optimizer' : optimizer, 'criterion' : criterion\n",
    "parameters = {**hyperparameters, **model_parameters}    # merge the two dictionairies\n",
    "pp = pprint.PrettyPrinter(indent=1)  \n",
    "\n",
    "\n",
    "pp.pprint(f'parameters: {parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training loop\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "userAccountID = cf.settings['userAccountID']\n",
    "saveFileName = f'{timestamp}_{userAccountID}.pt'\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"pineapple\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config= parameters\n",
    ")\n",
    "\n",
    "history = train(\n",
    "    model, train_loader, val_loader, criterion, optimizer, n_epochs=epochs,\n",
    "    model_file_name=saveFileName\n",
    ")\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n",
    "\n",
    "print()\n",
    "print(f'best results: {history[0]}')\n",
    "print()\n",
    "print(f'alot is: {history[1]}')\n",
    "print()\n",
    "print(f'save path = {history[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the training and validation loss\n",
    "axs[0].plot(history[1]['train_loss'], label='train_loss')\n",
    "axs[0].plot(history[1]['val_loss'], label='val_loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].set_title('Loss over training epochs')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "axs[1].plot(history[1]['train_acc'], label='train_acc')\n",
    "axs[1].plot(history[1]['val_acc'], label='val_acc')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy over training epochs')\n",
    "axs[1].legend()\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the save paths from history\n",
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the data to azure cosmos NoSQL database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_saved_path= list(history[2].values())[0]\n",
    "model_file_name_loss = list(history[2].values())[1]\n",
    "print(f'{list(history[2].values())[0]}/{list(history[2].values())[1]}')\n",
    "\n",
    "model_file_name_loss= f'{list(history[2].values())[0]}/{list(history[2].values())[1]}'\n",
    "print(model_file_name_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_file_name_loss= f'../{list(history[2].values())[0]}/{list(history[2].values())[1]}'\n",
    "model_file_name_acc = f'../{list(history[2].values())[0]}/{list(history[2].values())[2]}'\n",
    "model_file_name_final = f'../{list(history[2].values())[0]}/{list(history[2].values())[3]}'\n",
    "# model_file_name_loss= './20230605-103225_pinky_loss.pt' \n",
    "# model_file_name_acc = './20230605-103225_pinky_acc.pt'\n",
    "# model_file_name_final = './20230605-103225_pinky_final.pt'\n",
    "print(model_file_name_loss)\n",
    "print(model_file_name_acc)\n",
    "print(model_file_name_final)\n",
    "\n",
    "\n",
    "pulled_loss = cf.save_data(model_file_name_loss, parameters, history, )\n",
    "time.sleep(2)\n",
    "pulled_acc = cf.save_data(model_file_name_acc, parameters, history)\n",
    "time.sleep(2)\n",
    "pulled_final = cf.save_data(model_file_name_final, parameters, history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pulled_final)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP loader loads a wrong data type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pink_lady-bMzUwwsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
