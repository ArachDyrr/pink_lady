{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Net (CNN)\n",
    "to detect apples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import modules.cosmos_functions as cf\n",
    "\n",
    "import pprint\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as FF\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "from os import listdir, path\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is 'mps' Thus a tensor will look like this: tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# set the device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "x = torch.ones(1, device=device)\n",
    "\n",
    "print(f\"Device is '{device}' Thus a tensor will look like this: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def reverse_normalize(image):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    image = image.clone()\n",
    "    for i in range(3):\n",
    "        image[i] = (image[i] * std[i]) + mean[i]\n",
    "    return image\n",
    "\n",
    "def show_batch(train_d, test_d, val_d):\n",
    "    # Get a batch of data from the DataLoader\n",
    "    data_train = next(iter(train_d))\n",
    "    data_test = next(iter(test_d))\n",
    "    data_val = next(iter(val_d))\n",
    "\n",
    "    # Set the savefig.bbox parameter to 'tight'\n",
    "    plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "    # Retrieve the first tensor and its corresponding label\n",
    "    image_train = data_train[0][0]\n",
    "    image_test = data_test[0][0]\n",
    "    image_val = data_val[0][0]\n",
    "    label_train = data_train[1][0]\n",
    "    label_test = data_test[1][0]\n",
    "    label_val = data_val[1][0]\n",
    "\n",
    "    # Reverse the normalization of the images\n",
    "    image_train = reverse_normalize(image_train)\n",
    "    image_test = reverse_normalize(image_test)\n",
    "    image_val = reverse_normalize(image_val)\n",
    "\n",
    "    # Convert the image tensors to NumPy arrays and transpose the dimensions\n",
    "    np_image_train = image_train.permute(1, 2, 0).numpy()\n",
    "    np_image_test = image_test.permute(1, 2, 0).numpy()\n",
    "    np_image_val = image_val.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "    # Display the image in the first subplot\n",
    "    axes[0].imshow(np_image_train)\n",
    "    axes[0].set_title(f'{label_train}, {image_train.shape}')\n",
    "\n",
    "    # Display the image in the second subplot\n",
    "    axes[1].imshow(np_image_test)\n",
    "    axes[1].set_title(f'{label_test}, {image_test.shape}')\n",
    "\n",
    "    # Display the image in the third subplot\n",
    "    axes[2].imshow(np_image_val)\n",
    "    axes[2].set_title(f'{label_val}, {image_val.shape}')\n",
    "\n",
    "    # Adjust spacing between subplots to prevent overlap\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine accuracy \n",
    "\n",
    "def evaluate_accuracy(logits, y_true):\n",
    "    # get index with the largest logit value PER OBSERVATION\n",
    "    _, y_pred = torch.max(logits, dim=1)\n",
    "\n",
    "    # calculate proportion of correct prediction\n",
    "    correct_pred = (y_pred == y_true).float()  # PyCharm error Unresolved attribute reference 'float' for class 'bool'\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    return acc * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, n_epochs, model_file_name='model.pt',local_save_path='storage/data/generated'):\n",
    "    # initialize container variable for model performance results per epoch\n",
    "    history = {\n",
    "        'n_epochs': n_epochs,\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }   \n",
    "\n",
    "    # initialize tracker for minimum validation loss and maxiumum validation accuracy\n",
    "    val_loss_min = np.Inf\n",
    "    val_loss_epoch = 0\n",
    "    val_acc_max = 0.0\n",
    "    val_acc_epoch = 0\n",
    "    best_results = {\n",
    "        'val_loss_min': val_loss_min,\n",
    "        'val_loss_epoch': val_loss_epoch,\n",
    "        'val_acc_max': val_acc_max,\n",
    "        'val_acc_epoch': val_acc_epoch\n",
    "        }    \n",
    "\n",
    "    model_file_name_loss = f'{str(model_file_name[:-3])}_loss.pt'\n",
    "    model_file_name_acc = f'{str(model_file_name[:-3])}_acc.pt'\n",
    "    final_model_file_name = f'{str(model_file_name[:-3])}_final.pt'\n",
    "    locally_saved_path = local_save_path   \n",
    "\n",
    "    file_data = { \n",
    "                'local_save_path' : locally_saved_path,\n",
    "                'min_loss_file' : model_file_name_loss,\n",
    "                'max_acc_file' : model_file_name_acc,\n",
    "                'final_epoch_file' : final_model_file_name\n",
    "                  }\n",
    "    \n",
    "    model_safe_loss = f'../{locally_saved_path}/{model_file_name_loss}'\n",
    "    model_safe_acc = f'../{locally_saved_path}/{model_file_name_acc}'\n",
    "    model_safe_final = f'../{locally_saved_path}/{final_model_file_name}'\n",
    "\n",
    "    # loop per epoch\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        \n",
    "        # initialize tracker for training performance\n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "\n",
    "        # prepare model for training\n",
    "        model.train()\n",
    "\n",
    "        # loop for each batch\n",
    "        for data, target in train_loader:\n",
    "            # move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # STEP 1: clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # STEP 2: forward pass\n",
    "            output = model(data)\n",
    "            # STEP 3: calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # STEP 4: backward pass\n",
    "            loss.backward()\n",
    "            # STEP 5: perform parameter update\n",
    "            optimizer.step()\n",
    "            # STEP 6: accumulate training loss and accuracy\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            acc = evaluate_accuracy(output, target)\n",
    "            train_acc += acc.item() * data.size(0)\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "\n",
    "        # disable gradient calculation\n",
    "        with torch.no_grad():\n",
    "            # initialize tracker for validation performance\n",
    "            val_acc = 0\n",
    "            val_loss = 0\n",
    "\n",
    "            # prepare model for evaluation\n",
    "            model.eval()\n",
    "\n",
    "            # loop for each batch\n",
    "            for data, target in val_loader:\n",
    "                # move data to device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # STEP 1: forward pass\n",
    "                output = model(data)\n",
    "                # STEP 2: calculate the loss\n",
    "                loss = criterion(output, target)\n",
    "                # STEP 3: accumulate validation loss and accuracy\n",
    "                val_loss += loss.item() * data.size(0)\n",
    "                acc = evaluate_accuracy(output, target)\n",
    "                val_acc += acc.item() * data.size(0)\n",
    "\n",
    "\n",
    "        ####################\n",
    "        # model evaluation #\n",
    "        ####################\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss /= len(train_loader.sampler)\n",
    "        val_loss /= len(val_loader.sampler)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        # calculate average accuracy over an epoch\n",
    "        train_acc /= len(train_loader.sampler)\n",
    "        val_acc /= len(val_loader.sampler)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        # print training progress per epoch\n",
    "        print(f'Epoch {epoch+1:03} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.2f} | Val Acc: {val_acc:.2f}')\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if val_loss <= val_loss_min:\n",
    "            print(\n",
    "                f'Validation loss decreased ({val_loss_min:.5f} --> {val_loss:.5f})  Saving model to {model_file_name}...')\n",
    "            \n",
    "\n",
    "            torch.save(model.state_dict(), model_safe_loss)\n",
    "            val_loss_min = val_loss\n",
    "            best_results['val_loss_min'] = val_loss_min\n",
    "            best_results['val_loss_epoch'] = epoch+1\n",
    "        \n",
    "        # save model if validation accuracy has decreased\n",
    "        if val_acc >= val_acc_max:\n",
    "            print(\n",
    "                f'Validation accuracy increased ({val_acc_max:.5f} --> {val_acc:.5f})  Saving model to {model_file_name}...')\n",
    "              \n",
    "            torch.save(model.state_dict(), model_safe_acc)\n",
    "            val_acc_max = val_acc\n",
    "            best_results['val_acc_max'] = val_acc_max\n",
    "            best_results['val_acc_epoch'] = epoch+1\n",
    "\n",
    "        # log metrics to wandb\n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \"train_acc\": train_acc, \"val_acc\": val_acc})\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(), model_safe_final)\n",
    "\n",
    "    results = best_results, history, file_data\n",
    "    \n",
    "    # return model performance history\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blotch_Apple': 0, 'Normal_Apple': 1, 'Rot_Apple': 2, 'Scab_Apple': 3}\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset_path = \"../storage/images/apple_disease_classification/Train\"\n",
    "# transform and normalize the data\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "dataset.class_to_idx\n",
    "pp = pprint.PrettyPrinter(indent=1)  # Create a PrettyPrinter instance with an indentation of 1 space\n",
    "pp.pprint(dataset.class_to_idx)  # Use the pprint method to print the dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "267\n",
      "58\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "# create the test, train and validation set and the dataloader\n",
    "\n",
    "# setup split data \n",
    "dataset_size = len(dataset)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "\n",
    "# Set the seed for the generator\n",
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "\n",
    "# Define the batch size for the DataLoader\n",
    "batch_size = 248\n",
    "\n",
    "# Create the DataLoader to load the dataset in batches\n",
    "train_d = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, Drop_last)\n",
    "test_d = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_d = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# print the shape of the 1st image in the dataset\n",
    "print(train_dataset[0][0].shape)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))\n",
    "# # Show the 1st img in the dataset\n",
    "# show_batch(train_d, test_d,val_d)\n",
    "# print(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    def __init__(self, dropout=0):\n",
    "        self.dropout = dropout\n",
    "        \n",
    "\n",
    "        # Because we inherit from Module base class\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB input, 6 filters, kernel of 5 x 5\n",
    "        self.conv1 = nn.Conv2d(3, 9, 5)\n",
    "        \n",
    "        # Filter is 2 x 2 with a stride of 2 (defined once, used two times)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # in_channels = 6 because self.conv1 output has 6 channels\n",
    "        self.conv2 = nn.Conv2d(9, 16, 5)\n",
    "        \n",
    "        # Fully connected layer matched on output of conv2 layer\n",
    "        # self.fc1 = nn.Linear(16 * 13 * 13, 120)  # 64x64\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120)  # 224x224\n",
    "        \n",
    "        # Dropout layer1\n",
    "        self.dropout1 = nn.Dropout(self.dropout)    \n",
    "\n",
    "        # Dropout layer2\n",
    "        self.dropout2 = nn.Dropout(self.dropout)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # We only have 4 labels\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "        \n",
    "    #-------------------------------------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution with relu layers\n",
    "        x = self.pool(FF.relu(self.conv1(x)))\n",
    "        x = self.pool(FF.relu(self.conv2(x)))\n",
    "        \n",
    "        # To match the output of the conv2 layer onto the first fully connected layer\n",
    "        # Like reshape() but makes no copy (reuses underlaying data)\n",
    "        # x = x.view(-1, 16 * 13 * 13)  # 64*64\n",
    "        x = x.view(-1, 16 * 56 * 56)  # 224*224\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = FF.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = FF.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # return a softmax on dimention 1 (the normal apples) to see if an apple is rotten or not. \n",
    "        return F.softmax(self.fc3(x), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"parameters: {'learning_rate': 0.01, 'epochs': 6, 'momentum': 0.9, 'dropout': \"\n",
      " \"0.3, 'model': 'cnn', 'optimizer': 'SGD', 'criterion': 'CrossEntropyLoss'}\")\n"
     ]
    }
   ],
   "source": [
    "# set the hyperparameters and the model\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 6\n",
    "momentum = 0.9\n",
    "total_epochs =0\n",
    "dropout = 0.3\n",
    "\n",
    "\n",
    "# model parameters\n",
    "\n",
    "model = CNN(dropout=dropout) # Create the model\n",
    "model.to(device) # set model to device\n",
    "model.train() # set model to train mode\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()   # Define the loss function  \n",
    " \n",
    " # set the loaders to the correct names for the training loop\n",
    "train_loader = train_d\n",
    "val_loader = val_d\n",
    "\n",
    "# set epochloss to empty list\n",
    "epoch_loss = []\n",
    "# create dictionairies for the hyperparameters and model parameters\n",
    "hyperparameters = { 'learning_rate' : learning_rate, 'epochs' : epochs, 'momentum' : momentum, 'dropout' : dropout}\n",
    "model_parameters = { 'model' : 'cnn', 'optimizer' : 'SGD', 'criterion' : 'CrossEntropyLoss'}  # 'model' : model, 'optimizer' : optimizer, 'criterion' : criterion\n",
    "parameters = {**hyperparameters, **model_parameters}    # merge the two dictionairies\n",
    "pp = pprint.PrettyPrinter(indent=1)  \n",
    "\n",
    "\n",
    "pp.pprint(f'parameters: {parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1021548\u001b[0m (\u001b[33mteamnan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/stephandekker/workspace/pink_lady/factory/wandb/run-20230607_103451-7cm5ke24</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teamnan/my-awesome-project/runs/7cm5ke24' target=\"_blank\">legendary-flower-3</a></strong> to <a href='https://wandb.ai/teamnan/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teamnan/my-awesome-project' target=\"_blank\">https://wandb.ai/teamnan/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teamnan/my-awesome-project/runs/7cm5ke24' target=\"_blank\">https://wandb.ai/teamnan/my-awesome-project/runs/7cm5ke24</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:17<01:28, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 1.37845 | Val Loss: 1.39022 | Train Acc: 25.47 | Val Acc: 29.82\n",
      "Validation loss decreased (inf --> 1.39022)  Saving model to 20230607-103450_pinky.pt...\n",
      "Validation accuracy increased (0.00000 --> 29.82456)  Saving model to 20230607-103450_pinky.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:34<01:09, 17.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Train Loss: 1.37473 | Val Loss: 1.38485 | Train Acc: 32.58 | Val Acc: 45.61\n",
      "Validation loss decreased (1.39022 --> 1.38485)  Saving model to 20230607-103450_pinky.pt...\n",
      "Validation accuracy increased (29.82456 --> 45.61403)  Saving model to 20230607-103450_pinky.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:52<00:52, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Train Loss: 1.36317 | Val Loss: 1.38327 | Train Acc: 40.82 | Val Acc: 47.37\n",
      "Validation loss decreased (1.38485 --> 1.38327)  Saving model to 20230607-103450_pinky.pt...\n",
      "Validation accuracy increased (45.61403 --> 47.36842)  Saving model to 20230607-103450_pinky.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:09<00:34, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Train Loss: 1.35653 | Val Loss: 1.37932 | Train Acc: 44.19 | Val Acc: 47.37\n",
      "Validation loss decreased (1.38327 --> 1.37932)  Saving model to 20230607-103450_pinky.pt...\n",
      "Validation accuracy increased (47.36842 --> 47.36842)  Saving model to 20230607-103450_pinky.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:26<00:17, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Train Loss: 1.34369 | Val Loss: 1.36698 | Train Acc: 41.57 | Val Acc: 47.37\n",
      "Validation loss decreased (1.37932 --> 1.36698)  Saving model to 20230607-103450_pinky.pt...\n",
      "Validation accuracy increased (47.36842 --> 47.36842)  Saving model to 20230607-103450_pinky.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:43<00:00, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Train Loss: 1.32458 | Val Loss: 1.34089 | Train Acc: 40.45 | Val Acc: 36.84\n",
      "Validation loss decreased (1.36698 --> 1.34089)  Saving model to 20230607-103450_pinky.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▄▇█▇▇</td></tr><tr><td>train_loss</td><td>██▆▅▃▁</td></tr><tr><td>val_acc</td><td>▁▇███▄</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>40.44944</td></tr><tr><td>train_loss</td><td>1.32458</td></tr><tr><td>val_acc</td><td>36.84211</td></tr><tr><td>val_loss</td><td>1.34089</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-flower-3</strong> at: <a href='https://wandb.ai/teamnan/my-awesome-project/runs/7cm5ke24' target=\"_blank\">https://wandb.ai/teamnan/my-awesome-project/runs/7cm5ke24</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230607_103451-7cm5ke24/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best results: {'val_loss_min': 1.3408935070037842, 'val_loss_epoch': 6, 'val_acc_max': 47.36842346191406, 'val_acc_epoch': 5}\n",
      "\n",
      "alot is: {'n_epochs': 6, 'train_loss': [1.3784521206487876, 1.3747329747632202, 1.3631685284639565, 1.3565308686052815, 1.3436879482162132, 1.3245801447929069], 'val_loss': [1.390223741531372, 1.3848540782928467, 1.383274793624878, 1.3793230056762695, 1.3669829368591309, 1.3408935070037842], 'train_acc': [25.46816489401828, 32.58426964863409, 40.823970137463974, 44.19475665431791, 41.57303380787596, 40.449438230821706], 'val_acc': [29.824560165405273, 45.61403274536133, 47.36842346191406, 47.36842346191406, 47.36842346191406, 36.842105865478516]}\n",
      "\n",
      "save path = {'local_save_path': 'storage/data/generated', 'min_loss_file': '20230607-103450_pinky_loss.pt', 'max_acc_file': '20230607-103450_pinky_acc.pt', 'final_epoch_file': '20230607-103450_pinky_final.pt'}\n"
     ]
    }
   ],
   "source": [
    "# the training loop\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "userAccountID = cf.settings['userAccountID']\n",
    "saveFileName = f'{timestamp}_{userAccountID}.pt'\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config= parameters\n",
    ")\n",
    "\n",
    "history = train(\n",
    "    model, train_loader, val_loader, criterion, optimizer, n_epochs=epochs,\n",
    "    model_file_name=saveFileName\n",
    ")\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n",
    "\n",
    "print()\n",
    "print(f'best results: {history[0]}')\n",
    "print()\n",
    "print(f'alot is: {history[1]}')\n",
    "print()\n",
    "print(f'save path = {history[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the training and validation loss\n",
    "axs[0].plot(history[1]['train_loss'], label='train_loss')\n",
    "axs[0].plot(history[1]['val_loss'], label='val_loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].set_title('Loss over training epochs')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "axs[1].plot(history[1]['train_acc'], label='train_acc')\n",
    "axs[1].plot(history[1]['val_acc'], label='val_acc')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_title('Accuracy over training epochs')\n",
    "axs[1].legend()\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the save paths from history\n",
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the data to azure cosmos NoSQL database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_saved_path= list(history[2].values())[0]\n",
    "model_file_name_loss = list(history[2].values())[1]\n",
    "print(f'{list(history[2].values())[0]}/{list(history[2].values())[1]}')\n",
    "\n",
    "model_file_name_loss= f'{list(history[2].values())[0]}/{list(history[2].values())[1]}'\n",
    "print(model_file_name_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_file_name_loss= f'../{list(history[2].values())[0]}/{list(history[2].values())[1]}'\n",
    "model_file_name_acc = f'../{list(history[2].values())[0]}/{list(history[2].values())[2]}'\n",
    "model_file_name_final = f'../{list(history[2].values())[0]}/{list(history[2].values())[3]}'\n",
    "# model_file_name_loss= './20230605-103225_pinky_loss.pt' \n",
    "# model_file_name_acc = './20230605-103225_pinky_acc.pt'\n",
    "# model_file_name_final = './20230605-103225_pinky_final.pt'\n",
    "print(model_file_name_loss)\n",
    "print(model_file_name_acc)\n",
    "print(model_file_name_final)\n",
    "\n",
    "\n",
    "pulled_loss = cf.save_data(model_file_name_loss, parameters, history, )\n",
    "time.sleep(2)\n",
    "pulled_acc = cf.save_data(model_file_name_acc, parameters, history)\n",
    "time.sleep(2)\n",
    "pulled_final = cf.save_data(model_file_name_final, parameters, history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pulled_final)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP loader loads a wrong data type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pink_lady-bMzUwwsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
